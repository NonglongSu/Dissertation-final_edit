\chapter{\normalfont EM TRAINING OF AN INDEL-PHASE PROBABILISTIC MODEL}
\label{ch:indel_phase_model}


\section{Introduction}
Enormous amounts of data has been generated in the last decades due to the advancement of sequencing technology and bioinformatic tools. The corresponding models and algorithms are also developed to provide solutions to biological and bioinformatic problems. However, probabilistic-based models for indels are far less developed compared with the substitution models. In chapter 3, while I applied a sliding-window method to do the post-aligning indel phase fixation, the proportion of indel phases cannot represent the actual indel rates over the evolutionary time. To solve this, I developed an indel-phase probabilistic model that describes both substitution and indel processes. And I developed a novel EM training method that was capable of estimating the instantaneous indel rates of different phases,  indel length distribution, nucleotide exchangeabilities, non-synonymous selective coefficient, and branch length. The simulation results demonstrated the feasibility and accuracy of our EM algorithm for training the indel-phase model.

Many previous papers study the estimation of indel rates and indel length distribution. For instance, \cite{metzler2001assessing} reduced the alignment variability by sampling sequence alignments and estimating the indels from their joint posterior distribution. \cite{holmes2005using} proposed an EM method of estimating the indel parameters derived from the TKF91 model in multiple sequence alignments. \cite{cartwright2009problems} presented an EM algorithm built on a pair hidden Markov model handling indels in neutrally evolving DNA sequences. In those studies, while the indel rates were derived from the observed gap counts between alignments, a single gap actually reflected the possibility of multiple indel events and misled the computation of sequence likelihood. 

Two main distributions were utilized for describing the indel length: geometric and Zipfian (one of a family of related discrete power law probability distributions). Although there was evidence that Zipfian distribution fitted better with the biological datasets in both coding \parencite{benner1993empirical} and non-coding regions \parencite{saitou1994evolutionary}, geometric distribution was computationally tractable and easily calculated. Many researches accentuated the difference between insertions and deletions(\cite{tao2007patterns,metzgar2002domain}). They utilized pseudogenes or outgroups to distinguish insertions from deletions, which might increase the memory cost and restrict the data volume. However, due to the lack of outgroup sequence in my research, I randomly selected one of the two sequences as the ancestor, and the other one was automatically assigned as the descendant when calculating the sequence likelihood,. 

The existing methods of training the probabilistic models for indel evolution normally assume a single indel rate for all gaps between sequences, equal length distributions between insertions and deletions; and introduction of alignment bias (\cite{holmes2005using, lunter2007probabilistic, cartwright2009problems}). Here, I introduced several improvements in our indel-phase model study: 1) our indel-phase model proposed three rates of each indel phase instead of one rate for all indel events; 2) this model is richer because of the inclusion of the GTR+MG94 model for describing the substitution process; 3) During the EM training of the indel-phase model, the alignment bias was greatly removed through applying an importance sampling method. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods and Materials} 
\subsection{Indel-phase Model}
\paragraph{Indel-phase model} The indel-phase model was designed as a Moore machine with a finite number of states, whose current output was determined by its current state through a transition function \parencite{giantamidis2021learning}. In my research, I splitted our alignment into three independently ordered processes --- deletion (Fig 4.1 a), substitution (Fig 4.1 b), and insertion (Fig 4.1 c), where each has their own Moore machinery pathway and transitional weight between states. The evolutionary order of  deletion $\rightarrow$ substitution $\rightarrow$ insertion makes our model symmetric, which means the calculation of the aligning likelihood stays invariant, unnecessary to know which one of the sequences is ancestor/descendent. Because the synonymous/non-synonymous mutation type of a codon stays invariant no matter which sequence to start for calculating the likelihood. 
\newpage
\begin{figure}[H]
    \centering
     \begin{minipage}[t]{1\textwidth}
     \begin{subfigure}{\textwidth}
      \includegraphics[width=\linewidth]{Fig1.1.pdf}
      \subcaption{For deletions, there are three phases of deletion states ($D0_i,D1_i,D2_i$) corresponding to each position of the codon, where $i$ denotes the position of the matching state respectively. If the sequence is in the deleting state, it can either keep deleting the gaps in the unit of codon (the extending probability is $e$) or exit the gap state and go to the next matching state (the transition probability is $1-e$)}
     \end{subfigure}
    \end{minipage}
\end{figure}
%
\begin{figure}[H]\ContinuedFloat
    \centering
     \begin{minipage}[t]{1\textwidth}
     \begin{subfigure}{\textwidth}
      \includegraphics[width=\linewidth]{Fig1.2.pdf}
      \subcaption{For substitutions, the probability of codon i change to codon j equals the codon substitution matrix $P = e^{Rt}$, where R is the instantaneous rate matrix derived from the GTR+MG94 model and t is the evolutionary branch length between species. The figure above displays that the substitution jumps from matching state 1 to 4 directly, suggesting that our substitution matrix is in the unit of codon instead of nucleotide. }
     \end{subfigure}
    \end{minipage}
\end{figure}
%
\begin{figure}[H]\ContinuedFloat
    \centering
     \begin{minipage}[t]{1\textwidth}
     \begin{subfigure}{\textwidth}
       \includegraphics[width=\linewidth]{Fig1.3.pdf}
      \subcaption{For insertions, there are three phases of insertion states ($I0_i,I1_i,I2_i$), corresponding to each position of the codon. If the sequence is in the inserting state, it can either keep inserting the gaps in the unit of codon (the extending probability is $e$) or exit the gap state and go to the next matching state (the transition probability is $1-e$).  }
     \end{subfigure}
     \caption{Moore Machine Pathway of the Indel-phase Model}
    \end{minipage}
\end{figure}
%
Of note, I must assign an end edge transitional weight for deletion, substitution, and insertion machines respectively. If a codon chooses to end in a deletion state, suggesting no further action is needed and the transitional weight is 1. If a codon chooses to end in a matching state, suggesting that no phase-0 insertion action is allowed to occur, which means the transitional weight is $1-i_0$. If a codon chooses to end in an insertion state, suggesting that the machine must exit the current inserting bubble with a transitional weight of $1-e$. 

\paragraph{6nt alignment example} Suppose that there is a 6 nt alignment: 
$$\begin{matrix}
 A & - & - & - & A & A & A & A & A \\
 A & A & A & A & A & - & - & - & T \\
 * &   &   &   & * &   &   &   & * 
\end{matrix}$$
where $*$ represents the substitution codon. In order to calculate the likelihood of this alignment, I need to split the calculation into three processes. For deletions, the machinery pathway is $1 \rightarrow 2 \rightarrow3 \rightarrow D2_4 \rightarrow D2_5 \rightarrow D2_6 \rightarrow 7$, with a transitional probability of $(1-d_0)(1-d_1)(d_2)(1-e)$. For substitution, the machinery pathway is $1 \rightarrow 4$, with a substitution probability of $P(AAT|AAA)$ that is calculated from the matrix exponential of the MG94+GTR model. For insertion, the machinery pathway is $ 1 \rightarrow 2 \rightarrow I1_2 \rightarrow 3 \rightarrow 4$, with a transitional probability of $(1-i_0)(i_1)(1-e)(1-i_2)$. The total likelihood of this sequence is the sum of the above three likelihoods together. 


\subsection{Indel Rates}
Abstractly, we treat gaps as one or more overlapping or neighboring indels assembling together, whereas an indel is a specific evolutionary event that adds or deletes residues from a sequence. Without ancestor lineage reference, a gap in the alignment of one sequence may be caused by either one or more deletions in that sequence or one or more insertions in the other sequence. Popular methods like maximum parsimony tend to reassemble adjoining single indel events so that the alignment scores can be maximized, which underestimates the true indel rate along an evolutionary branch \cite{knudsen2003sequence}. To simplify the model, I treat a single gap from the alignments as a single indel event. Next, the model assumes both substitutions and indels follow a continuous-time Poisson process. If the chain does not terminate, the probability of the next state of I or D is $g_i = 1-e^{r_i t}$, where $r_i$ is the instantaneous indel rate of phase i relative to substitution rate, t is the branch length between pairwise sequences measured in expected number of  substitutions per base pair. SO the $e^{r_i t}$ represents the probability that no indel events have occurred.

\subsection{Indel Length Distribution}
I assumed the length of insertions and deletions followed different geometric distributions in our model. The maximum likelihood estimate of gap extension weight $e_i, e_d$ is calculated by $ 1-1/\hat{g_s}$, where $\hat{g_s}$ represented the average gap size of insertions and deletions separately (dividing the sum of gap length by the total number of gaps).   

\subsection{Codon Substitution Model}
The substitution matrix $R_{ij}$ was represented by the MG94 +GTR codon substitution model (\cite{muse1994likelihood, tavare1986some}), and the details about the matrix construction can be found in the methods of chapter 2. 

\subsection{Coati-sampling Method}
To fulfill the purpose of aligning coding sequences as codons but also allows indels within codons, I select the Coati-sampling aligner that is built on the Forward algorithm within the context of Hidden Markov model developed by our lab (\href{https://github.com/jgarciamesa/coati}{https://github.com/jgarciamesa/coati}). This aligner has no restrictions for gap locations, options for forcing the gap length to be multiple of three nucleotides, and more importantly, allows to generate many sample alignments for a single pairwise sequence with a sequence likelihood.  

\subsection{EM Method}
I used the EM method to find the local maximum likelihood estimates of parameters. The E-step generated a function for the expectation of the log-likelihood: 
\begin{equation}
\label{Ziqi_LL}
\begin{split}
Q(\theta|\theta_{t}) 
 &= \sum_{i}\sum_{j} D_{ij}log(P_{ij})\\
 &+ N_0log(g_0) + N_1log(g_1) + N_2log(g_2) \\
 &+ M_0log(1-g_0) + M_1log(1-g_1) + M_2log(1-g_2) \\
 &+ (L_i - N_i)log(e_i) + N_{i}log(1-e_i) +  (L_d - N_d)log(e_d) + N_{d}log(1-e_d)\\
 &- \sum_{1}^n log(\Pi_{k}) - \sum_{1}^m log(\Pi_{k})
 \end{split}
\end{equation}
where $D_{ij}$ is the codon substitutions $i \rightarrow j$ observed from data, $P_{i,j}$ is the codon substitution matrix from i to j ($1 <= j <= 64$), which is calculated as the exponential of the rate matrix $R_{ij}$. $N_0$, $N_1$, $N_2$ is the total number of gaps phase0, phase1, and phase2, $g_0$, $g_1$, $g_2$ is the gap openings of three phases. $M_0$, $M_1$, $M_2$ is the total number of non-gap phases, which equals the difference between codon lengths and number of gap phases. $L_i$, $L_d$ are the total length of inserting gaps and deleting gaps, $N_i$, $N_d$ are the total number of inserting gaps and deleting gaps, $e_i$, $e_d$ is the gap extensions of insertion and deletion events. $\pi_k$ represents the nucleotide frequency of ancestor and descendent sequences in which the lengths are n and m. I removed their likelihood because they stayed invariant in all of the aligning samples. In addition, the E-step has a time complexity of number of sequences times sequence length O(500*100). Hence, I developed a grouping method within the E step to speed up the performance: 1) Dividing the groups to ensure that each group has identical alignments. 2) recording the likelihood of each group alignment; 3) extracting the number of groups and group size. 

The M-step maximizes that function with respect to the parameters $\theta$ via utilizing the summary statistics obtained from E-step. 
\begin{gather*}
              \theta_{t+1} = \underset{\theta}{argmax}Q(\theta |\theta_{t})
\end{gather*}
Where $\theta$ represents our parameter set \{$6\sigma s, \omega,\tau, g_i,e_i$\}. Gap opening weight $g_i$ and gap extension weight $e$ was solved by taking the first derivative of likelihood function Q and the value was $N_i/(N_i+M_i)$ and $1-1/(L/N)$ respectively. For practical purposes, I utilized the Nmkb derivative-free optimization method to obtain the estimates of substitution models within M-step. Finally, I used the root mean square error ($<10^{-4}$) between the joint estimates and true parameters as the stop criterion for the EM process.    

\subsection{Importance Sampling}
Doing the sum over all possible alignments for the indel-phase model is expensive due to the indels happening inside codons. Instead I utilized COATi to sample alignments and applied an importance sampling method to estimate the required statistics for the EM. Importance sampling is a statistical technique that is used to estimate the properties of a particular distribution without sampling from that distribution directly. \parencite{kloek1978bayesian}. In our research, two distinctive distributions are from the indel-phase model and coatiM model respectively. The indel-phase model is capable of calculating the likelihood of the alignment without actually generating the alignment samples. For example, I was able to obtain 100 samples from each unaligned pairwise sequence after the coati alignments, and calculated their sequence likelihood g(x). Then I generated a second likelihood value f(x) of the same alignments from our indel-phase model. The likelihood ratio of f(x)/g(x) is called the importance weight w, which is the key for correcting the distribution difference between two models. Because it always encourages a higher weight to frequently occurring aligning samples. For example, for a 100 alignment samples $A_i$, the average weighted number of gaps  is $\hat N$=$\sum_{i}^n w_i N(A_i) /100$. Additionally, for the convenience of calculation, we used the normalized importance weight instead of the raw weight, because sometimes I can only compute w up to a proportionality constant. 

\subsection{Parameter Space}
I need to assign an appropriate weight space for our true parameters $\{\pi, \sigma, \tau, \omega, g_i, e\}$.1) The four nucleotide frequencies $\pi$, six nucleotide exchangeabilities $\sigma$ , and selective strength on non-synonymous substitutions $\omega$, are generated via the same methods of chapter 2. This time I selected a smaller $\tau$ value to avoid the possibility of overlapping indels. 2) The gap opening weight are represented by the formula $1-e^{r t}$ with indel rate r, in which the indel rate is about 12-16 indels per 100 substitutions according to \cite{cartwright2009problems}. And the indel rates of three phases are mutually independent and within the range \{0.05,0.15\} when the substitution rate is normalized as 1. 3) The gap extensions are represented by the average gap size of $1-1/g_s$, where $g_s$ is determined in the unit of codons instead of nucleotides. I selected a boundary of gap size \{1,4\}, ensuring that the gap extension weights were always positive, and the largest gap was the same as the size used in the sliding window method of chapter 3.  

\subsection{Gillespie Simulation}
I need to simulate a series of true alignment based on my generated true parameters. \cite{gillespie1977exact} proposed an algorithm that was able to generate a statistically correct trajectory of a stochastic equation system, which has been applied on simulating the evolutionary process of a single DNA sequence \parencite{sipos2011phylosim}. The probability of a random event occurring equals the $r_i/(\sum_{i=1}^n r_i)$. Our gillespie algorithm separates all three processes (deletion, substitution, insertion) to make it easier to estimate parameters. Without separation there would be ambiguity when multiple events happen at one codon. 

There are several key points about our gillespie algorithm: 1) since both mutations and indels follow a continuous-time Poisson distribution, I must use the same branch length $\tau$ for all three independent processes (deletion, substitution, and insertion). 2) Different indel phases can occur at different rates r0, r1, r2. 3) The indel lengths are a multiple of three nucleotides and follow a geometric distribution. Inserted nucleotides are drawn from the stationary distribution of nucleotide frequencies. 4) No substitutions will occur inside the inserted fragments. 5) The total number of inserting positions is n+1, if the sequence length were n. The first inserting position is on the left side of the first nucleotide, which is normally called the immortal link. The total number of deleting positions equals the sequence length n \parencite{thorne1991evolutionary}. 6) Alignments are normalized such that insertions occur before deletions of the same indel phase. 7) The evolutionary order of our Gillespie simulation is deletion $\rightarrow$ substitution $\rightarrow$ insertion, because this is a symmetric model for calculating likelihood. It guarantees that the evolutionary track of a substitution process never gets wiped out because the mutational type (synonymous or nonsynonymous) of a codon surrounding an indel stays unchanged after the alignment. 8) The waiting time between each evolutionary event follows an exponential distribution, and the simulation process stops until the accumulated time passes our branch length $\tau$. 

   


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
\subsection{Gillespie Simulation Results}
To establish a baseline for the performance of our method, we generated a qqplot for each parameter. Figure 4.2 displays the correlation between the true parameters and parameter estimates from gillespie simulated alignments. The diagonal line measures the accuracy between the true and estimated parameters. Since the Gillespie simulation only generates the true alignment, their differences are due to the randomness of the simulation process instead of any systematic error. 
\begin{figure}[H]
     \centering
     \begin{minipage}[t]{1\textwidth}
     \includegraphics[width=1\linewidth,height=1.2\linewidth]{Fig2.pdf}
     \titlecaption{QQplot of 13 Parameters via Gillespie Simulation.}
     { {True parameter values are on the x-axis and parameter estimates are on the y-axis, including Six $\sigma$s, $\tau$, $\omega$, gap extensions $e_i$, $e_d$, and three indel phase rates $r0$, $r1$, $r2$.}
 \par}
     \end{minipage}
\end{figure}
\newpage

Figure 4.3 displays the distribution of error percentage between the true and estimated parameters across 100 simulations. I measured the error percentage as an absolute value of (true-est)/true and was always positive. The mean value of error percentage is extremely low as well as the variance. For example, the lowest and highest mean value of  error percentage is 0.013 ($\tau$), and 0.027 ($r_0$) (table \ref{tab:error_stat1_cha3}).
\begin{figure}[H]
     \centering
     \begin{minipage}[t]{1\textwidth}
     \includegraphics[width=1\linewidth,height=1\linewidth]{Fig3.pdf}
     \titlecaption{Error Percentage Distribution Plot of 13 Parameters via Gillespie Simulation.}
     { {Each color represents a parameter estimate.} 
 \par}
     \end{minipage}
\end{figure}

\newpage
\begin{xltabular}{\textwidth}{X| X X X X X X X X X X X X X}
\toprule
& $\sigma_{AC}$ & $\sigma_{AG}$ & $\sigma_{AT}$ & $\sigma_{CG}$ & $\sigma_{CT}$ & $\sigma_{GT}$ & $\omega$ & $\tau$ & $e_i$ & $e_d$ & r0 & r1 & r2 \\
\midrule
\csvreader[]{cha3/table/error_stat1.csv}{}
{\\ \csvcoli & \csvcolii &\csvcoliii &\csvcoliv &\csvcolv &\csvcolvi &\csvcolvii &\csvcolviii
&\csvcolix &\csvcolx &\csvcolxi &\csvcolxii &\csvcolxiii &\csvcolxiv}
\\ \bottomrule
\titlecaption{The Mean and Variance Table of Error Percentage of Parameters from Gillespie Simulation}{$\mu$ and s represent the mean and variance value.}
\end{xltabular}
\label{tab:error_stat1_cha3}

\subsection{EM + Importance Sampling Results}
To examine the performance of our importance sampling method and the EM algorithm, I generated a qqplot for each parameter. Figure 4.4 displays the correlation between the true parameters and our parameters estimates . Almost every simulated point remains on the diagonal line. Since the importance sampling and EM method works on a series of unaligned sequences, the error percentage is considered as the combination of the randomness from Gillespie simulation and the sampling noise from our method. Theoretically, the more samples generated, the more accurate the parameter estimates are.   
\begin{figure}[H]
     \centering
     \begin{minipage}[t]{1\textwidth}
     \includegraphics[width=1\linewidth,height=1.2\linewidth]{Fig4.pdf}
     \titlecaption{QQplot of 13 Parameter Estimates via EM + Importance Sampling Method.}
     { {True parameter values are on the x-axis and parameter estimates are on the y-axis, including Six $\sigma$s, $\tau$, $\omega$, gap extensions $e_i$, $e_d$, and three indel phase rates $r0$, $r1$, $r2$.} 
 \par}
     \end{minipage}
\end{figure}

\newpage

Figure 4.5 displays the distribution of error percentage between the true and estimated parameters across 100 simulations. Similarly, the mean value and variance of error percentage for each parameter are extremely low. For instance, the range of the average error percentage value of 13 parameters is [0.013, 0.036] from $\tau$ and $r_0$ respectively (table \ref{tab:error_stat2_cha3}. 
\begin{figure}[H]
     \centering
     \begin{minipage}[t]{1\textwidth}
     \includegraphics[width=1\linewidth,height=1\linewidth]{Fig5.pdf}
     \titlecaption{Error Percentage Distribution Plot of 13 Parameters via EM + Importance Sampling Method.}
     { {Each color represents a parameter estimate.} 
 \par}
     \end{minipage}
\end{figure}

\newpage
\begin{xltabular}{\textwidth}{X| X X X X X X X X X X X X X}
\toprule
& $\sigma_{AC}$ & $\sigma_{AG}$ & $\sigma_{AT}$ & $\sigma_{CG}$ & $\sigma_{CT}$ & $\sigma_{GT}$ & $\omega$ & $\tau$ & $e_i$ & $e_d$ & r0 & r1 & r2 \\
\midrule
\csvreader[]{cha3/table/error_stat2.csv}{}
{\\ \csvcoli & \csvcolii &\csvcoliii &\csvcoliv &\csvcolv &\csvcolvi &\csvcolvii &\csvcolviii
&\csvcolix &\csvcolx &\csvcolxi &\csvcolxii &\csvcolxiii &\csvcolxiv}
\\ \bottomrule
\titlecaption{The Mean and Variance Table of Error Percentage of Parameters from EM + Importance Sampling Method}{$\mu$ and s represent the mean and variance value.}
\end{xltabular}
\label{tab:error_stat2_cha3}

\section{Discussion}
In order to understand the evolutionary process of substitution and indels together, I first conducted the Gillespie simulation to generate a series of simulated true alignments. Then I unaligned the true alignments and realigned them with the coati-sampler. Due to the complexity of the indel-phase model, I developed an EM + importance sampling method to train this model observed on the coati-sampling alignments, and measured the accuracy of the parameter estimates. The parameter estimates results demonstrate an excellent performance of the EM + importance sampling method of training my indel-phase model.    

It is worthy of pointing out that the parameter has the lowest average value of error percentage is the branch length $\tau$, and the highest one is phase0-indel rate $r_0$  in both Gillespie simulation and EM + importance sampling method. Because the substitution events occur much more frequently than the indels during the same evolutionary time. And the branch length $\tau$ actually measures the number of substitutions per site that is expected to be much higher than the number of indels per site. Similarly, the mean of error percentage of substitution parameters \{$6\sigma s, \omega, \tau $\} are lower than the indel parameters \{$r_0, r_1, r_2,  e_i, e_d $\} during the same evolutionary time. Those results suggest that the more data collected, the less the noise would be. 

In the future, I can vary the indel-phase model to obtain better performance. For example, I can utilize the zeta distribution instead of the traditional geometric distribution for indel length since \cite{cartwright2009problems} mentioned that the zeta power-law model might be a better fit based on many empirical studies. Additionally, I can convert our R scripts to C++ scripts to improve the computational speed for the EM training process, allowing us to increase the sample sizes to obtain more accurate parameter estimates.   







%\bibliographystyle{unsrtnat}
%\bibliography{ref3.bib}


